{"hash": "8266be28eff7a8fb9a05fbd476f6fe11fe97c898bcc6e0a9fd05f977272df362", "target": {"backend": "cuda", "arch": 120, "warp_size": 32}, "num_warps": 8, "num_ctas": 1, "num_stages": 1, "maxnreg": null, "cluster_dims": [1, 1, 1], "ptx_version": null, "ptx_options": null, "ir_override": null, "enable_fp_fusion": true, "launch_cooperative_grid": false, "launch_pdl": false, "supported_fp8_dtypes": ["fp8e4b15", "fp8e4nv", "fp8e5"], "deprecated_fp8_dot_operand_dtypes": ["fp8e4b15"], "default_dot_input_precision": "tf32", "allowed_dot_input_precisions": ["tf32", "tf32x3", "ieee"], "max_num_imprecise_acc_default": 0, "extern_libs": [["libdevice", "E:\\liliyuanshangmie\\Fuxkcomfy_lris_kernel_gen2-4_speed_safe\\python_embeded\\Lib\\site-packages\\triton\\backends\\nvidia\\lib\\libdevice.10.bc"]], "debug": true, "backend_name": "cuda", "sanitize_overflow": false, "arch": "sm120", "triton_version": "3.4.0", "tensordesc_meta": [], "shared": 96, "tmem_size": 0, "global_scratch_size": 0, "global_scratch_align": 1, "name": "triton_red_fused__scaled_mm__to_copy_add_addcmul_native_layer_norm_ones_6"}